{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youqihuang/Desktop/USC-SB-Transformer/.env/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(train_num_points=1000, valid_num_points=100, report_num_points=500, model_name='lstm', max_length=128, replace_size=3, batch_size=2, num_workers=0, epochs=1, lr=1e-05, gamma=1, vocab_size=7113, embedding_dim=300, hidden_dim=256, output_dim=3, num_layers=8, dropout=0.5, pad_idx=1)\n",
      "\n",
      " Property of dataset:\n",
      "train set size:  392702\n",
      "validation_matched set size:  9815\n",
      "validation_mismatched set size:  9832\n",
      "test_matched set size:  9796\n",
      "test_mismatched set size:  9847\n",
      "7113\n",
      "1205\n",
      "1205\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m    113\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMTextClassifier(args,foldername)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 114\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreplaced_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/USC-SB-Transformer/LSTM.py:146\u001b[0m, in \u001b[0;36mLSTMTextClassifier.train\u001b[0;34m(self, train_dataloader, valid_dataloader, replaced_dataloader, device)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation(valid_dataloader, replaced_dataloader,epoch,device,\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 146\u001b[0m temp1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msensitivity_2dlist_report\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m temp2\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_report, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    148\u001b[0m temp3 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_loss_report, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# %%\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "os.getcwd() \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "from test import *\n",
    "from utils import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import torch\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from RoBERTa import *\n",
    "from LSTM import *\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "import logging    # first of all import the module\n",
    "from datetime import datetime\n",
    "\n",
    "# %%\n",
    "\n",
    "foldername = datetime.now().strftime('./logs/%Y_%m_%d_%H_%M_%S')\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(foldername):\n",
    "    os.makedirs(foldername)\n",
    "# Define the log filename inside the newly created folder\n",
    "logfilename = os.path.join(foldername, 'logfile.log')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "parser.add_argument('--train_num_points', type=int,             default = 1000,              help='train data number')\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 100,              help='validation data number')\n",
    "parser.add_argument('--report_num_points',type=int,             default = 500,              help='report number')\n",
    "parser.add_argument('--model_name',       type=str,             default = 'lstm',   help='model name')\n",
    "parser.add_argument('--max_length',       type=int,             default=128,                help='max_length')\n",
    "parser.add_argument('--replace_size',     type=int,             default=3,                  help='to test sensitivity, we need to replance each word by x random words from vocab, here we specify the x')\n",
    "#TODO: default = 64\n",
    "parser.add_argument('--batch_size',       type=int,             default=2,                  help='Batch size')\n",
    "parser.add_argument('--num_workers',      type=int,             default=0,                  help='num_workers')\n",
    "parser.add_argument('--epochs',           type=int,             default=1,                  help='num of epochs')\n",
    "parser.add_argument('--lr',               type=float,           default=1e-5,               help='lr')\n",
    "parser.add_argument('--gamma',            type=float,           default=1,                  help='lr*gamma after each test')\n",
    "parser.add_argument('--vocab_size',       type=int,             default=7113,               help='size of vocabulary')\n",
    "parser.add_argument('--embedding_dim',    type=int,             default=300,               help='embedding dimension')\n",
    "parser.add_argument('--hidden_dim',       type=int,             default=256,                 help='hidden dimension')\n",
    "parser.add_argument('--output_dim',       type=int,             default=3,                 help='number of classes')\n",
    "parser.add_argument('--num_layers',       type=int,             default=8,                 help='number of layers')\n",
    "parser.add_argument('--dropout',          type=int,             default=0.5,                 help='dropout')\n",
    "parser.add_argument('--pad_idx',          type=int,             default=1,                 help='ignores token with this index')\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "print(args)\n",
    "\n",
    "dataset = load_dataset('glue', 'mnli')\n",
    "\n",
    "print('\\n Property of dataset:')\n",
    "print('train set size: ',len(dataset['train']))\n",
    "print('validation_matched set size: ',len(dataset['validation_matched']))\n",
    "print('validation_mismatched set size: ',len(dataset['validation_mismatched']))\n",
    "print('test_matched set size: ',len(dataset['test_matched']))\n",
    "print('test_mismatched set size: ',len(dataset['test_mismatched']))\n",
    "# %%\n",
    "# %%\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "train = dataset['train'][:args.train_num_points]\n",
    "valid = dataset['validation_matched'][-args.valid_num_points:]\n",
    "replaced = replaced_data(valid, args.replace_size) \n",
    "print(len(get_vocab(train)))\n",
    "print(len(get_vocab(valid)))\n",
    "print(len(get_vocab(valid)))\n",
    "\n",
    "if args.model_name=='roberta-scratch':\n",
    "    tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "elif args.model_name=='lstm':\n",
    "    import torchtext\n",
    "    tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "#mnli\n",
    "#The Multi-Genre Natural Language Inference Corpus is a crowdsourced collection of sentence pairs with textual entailment annotations. Given a premise sentence and a hypothesis sentence, the task is to predict whether the premise entails the hypothesis (entailment), contradicts the hypothesis (contradiction), or neither (neutral). The premise sentences are gathered from ten different sources, including transcribed speech, fiction, and government reports. The authors of the benchmark use the standard test set, for which they obtained private labels from the RTE authors, and evaluate on both the matched (in-domain) and mismatched (cross-domain) section. They also uses and recommend the SNLI corpus as 550k examples of auxiliary training data.\n",
    "\n",
    "# %%\n",
    "train_data = get_Dataset(train, tokenizer, args.model_name, max_length=args.max_length)\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "valid_data = get_Dataset(valid, tokenizer, args.model_name, max_length=args.max_length)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "# replaced_data = get_Replaced_Dataset(replaced, tokenizer, args.model_name, max_length = args.max_length)\n",
    "replaced_data = get_Dataset(valid, tokenizer, args.model_name, max_length=args.max_length)\n",
    "replaced_dataloader = DataLoader(replaced_data, sampler=SequentialSampler(replaced_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "\n",
    "# %%\n",
    "\n",
    "model = LSTMTextClassifier(args,foldername).to(device)\n",
    "model.train(train_dataloader,valid_dataloader,replaced_dataloader,device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_label_sensitivity(replaced_dataloader, original_dataloader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging    # first of all import the module\n",
    "from datetime import datetime\n",
    "\n",
    "logfilename = datetime.now().strftime('./logs/logfile_%H_%M_%d_%m_%Y.log')\n",
    "\n",
    "logging.basicConfig(filename=logfilename, filemode='w', format='%(name)s - %(levelname)s - %(message)s')\n",
    "logging.warning(\"warning\")\n",
    "logging.info(\"info\")\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
